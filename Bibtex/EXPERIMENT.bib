% Encoding: UTF-8

@Article{Gonzalez-Huerta2015,
  author        = {Javier Gonzalez-Huerta and Emilio Insfran and Silvia Abrahão and Giuseppe Scanniello},
  title         = {Validating a model-driven software architecture evaluation and improvement method: A family of experiments},
  journal       = {Information and Software Technology},
  year          = {2015},
  volume        = {57},
  pages         = {405 - 429},
  issn          = {0950-5849},
  __markedentry = {[mac:6]},
  abstract      = {Context
Software architectures should be evaluated during the early stages of software development in order to verify whether the non-functional requirements (NFRs) of the product can be fulfilled. This activity is even more crucial in software product line (SPL) development, since it is also necessary to identify whether the NFRs of a particular product can be achieved by exercising the variation mechanisms provided by the product line architecture or whether additional transformations are required. These issues have motivated us to propose QuaDAI, a method for the derivation, evaluation and improvement of software architectures in model-driven SPL development.
Objective
We present in this paper the results of a family of four experiments carried out to empirically validate the evaluation and improvement strategy of QuaDAI.
Method
The family of experiments was carried out by 92 participants: Computer Science Master’s and undergraduate students from Spain and Italy. The goal was to compare the effectiveness, efficiency, perceived ease of use, perceived usefulness and intention to use with regard to participants using the evaluation and improvement strategy of QuaDAI as opposed to the Architecture Tradeoff Analysis Method (ATAM).
Results
The main result was that the participants produced their best results when applying QuaDAI, signifying that the participants obtained architectures with better values for the NFRs faster, and that they found the method easier to use, more useful and more likely to be used. The results of the meta-analysis carried out to aggregate the results obtained in the individual experiments also confirmed these results.
Conclusions
The results support the hypothesis that QuaDAI would achieve better results than ATAM in the experiments and that QuaDAI can be considered as a promising approach with which to perform architectural evaluations that occur after the product architecture derivation in model-driven SPL development processes when carried out by novice software evaluators.},
  comment       = {25},
  doi           = {https://doi.org/10.1016/j.infsof.2014.05.018},
  keywords      = {Software architectures, Software architecture evaluation methods, Quality attributes, ATAM, Family of experiments, Meta-analysis},
  url           = {http://www.sciencedirect.com/science/article/pii/S0950584914001359},
}

@Article{Sinnema2008,
  author        = {Marco Sinnema and Sybren Deelstra},
  title         = {Industrial validation of COVAMOF},
  journal       = {Journal of Systems and Software},
  year          = {2008},
  volume        = {81},
  number        = {4},
  pages         = {584 - 600},
  issn          = {0164-1212},
  note          = {Selected papers from the 10th Conference on Software Maintenance and Reengineering (CSMR 2006)},
  __markedentry = {[mac:6]},
  abstract      = {COVAMOF is a variability management framework for product families that was developed to reduce the number of iterations required during product derivation and to reduce the dependency on experts. In this paper, we present the results of an experiment with COVAMOF in industry. The results show that with COVAMOF, engineers that are not involved in the product family were now capable of deriving the products in 100% of the cases, compared to 29% of the cases without COVAMOF. For experts, the use of COVAMOF reduced the number of iterations by 42%, and the total derivation time by 38%.},
  comment       = {17},
  doi           = {https://doi.org/10.1016/j.jss.2007.06.002},
  keywords      = {Product family engineering, Industrial validation, Software Variability Management},
  url           = {http://www.sciencedirect.com/science/article/pii/S0164121207001422},
}

@Article{Dermeval2015a,
  author        = {Diego Dermeval and Thyago Tenório and Ig Ibert Bittencourt and Alan Silva and Seiji Isotani and Márcio Ribeiro},
  title         = {Ontology-based feature modeling: An empirical study in changing scenarios},
  journal       = {Expert Systems with Applications},
  year          = {2015},
  volume        = {42},
  number        = {11},
  pages         = {4950 - 4964},
  issn          = {0957-4174},
  __markedentry = {[mac:6]},
  abstract      = {A software product line (SPL) is a set of software systems that have a particular set of common features and that satisfy the needs of a particular market segment or mission. Feature modeling is one of the key activities involved in the design of SPLs. The feature diagram produced in this activity captures the commonalities and variabilities of SPLs. In some complex domains (e.g., ubiquitous computing, autonomic systems and context-aware computing), it is difficult to foresee all functionalities and variabilities a specific SPL may require. Thus, Dynamic Software Product Lines (DSPLs) bind variation points at runtime to adapt to fluctuations in user needs as well as to adapt to changes in the environment. In this context, relying on formal representations of feature models is important to allow them to be automatically analyzed during system execution. Among the mechanisms used for representing and analyzing feature models, description logic (DL) based approaches demand to be better investigated in DSPLs since it provides capabilities, such as automated inconsistency detection, reasoning efficiency, scalability and expressivity. Ontology is the most common way to represent feature models knowledge based on DL reasoners. Previous works conceived ontologies for feature modeling either based on OWL classes and properties or based on OWL individuals. However, considering change or evolution scenarios of feature models, we need to compare whether a class-based or an individual-based feature modeling style is recommended to describe feature models to support SPLs, and especially its capabilities to deal with changes in feature models, as required by DSPLs. In this paper, we conduct a controlled experiment to empirically compare two approaches based on each one of these modeling styles in several changing scenarios (e.g., add/remove mandatory feature, add/remove optional feature and so on). We measure time to perform changes, structural impact of changes (flexibility) and correctness for performing changes in our experiment. Our results indicate that using OWL individuals requires less time to change and is more flexible than using OWL classes and properties. These results provide insightful assumptions towards the definition of an approach relying on reasoning capabilities of ontologies that can effectively support products reconfiguration in the context of DSPL.},
  comment       = {15},
  doi           = {https://doi.org/10.1016/j.eswa.2015.02.020},
  keywords      = {Feature modeling, Ontology, Software product line, Empirical software engineering},
  url           = {http://www.sciencedirect.com/science/article/pii/S0957417415001190},
}

@Article{Guana2013a,
  author        = {Victor Guana and Dario Correal},
  title         = {Improving software product line configuration: A quality attribute-driven approach},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {3},
  pages         = {541 - 562},
  issn          = {0950-5849},
  note          = {Special Issue on Software Reuse and Product Lines},
  __markedentry = {[mac:6]},
  abstract      = {Context
During the definition of software product lines (SPLs) it is necessary to choose the components that appropriately fulfil a product’s intended functionalities, including its quality requirements (i.e., security, performance, scalability). The selection of the appropriate set of assets from many possible combinations is usually done manually, turning this process into a complex, time-consuming, and error-prone task.
Objective
Our main objective is to determine whether, with the use of modeling tools, we can simplify and automate the definition process of a SPL, improving the selection process of reusable assets.
Method
We developed a model-driven strategy based on the identification of critical points (sensitivity points) inside the SPL architecture. This strategy automatically selects the components that appropriately match the product’s functional and quality requirements. We validated our approach experimenting with different real configuration and derivation scenarios in a mobile healthcare SPL where we have worked during the last three years.
Results
Through our SPL experiment, we established that our approach improved in nearly 98% the selection of reusable assets when compared with the unassisted analysis selection. However, using our approach there is an increment in the time required for the configuration corresponding to the learning curve of the proposed tools.
Conclusion
We can conclude that our domain-specific modeling approach significantly improves the software architect’s decision making when selecting the most suitable combinations of reusable components in the context of a SPL.},
  comment       = {22},
  doi           = {https://doi.org/10.1016/j.infsof.2012.09.007},
  keywords      = {Software architecture, Model driven – software product lines, Variability management, Quality evaluation, Sensitivity points, Domain specific modeling},
  url           = {http://www.sciencedirect.com/science/article/pii/S0950584912002017},
}

@Article{Asadi2016,
  author        = {Asadi, M. and Soltani, S. and Gašević, D. and Hatala, M.},
  title         = {The effects of visualization and interaction techniques on feature model configuration},
  journal       = {Empirical Software Engineering},
  year          = {2016},
  volume        = {21},
  number        = {4},
  pages         = {1706-1743},
  note          = {cited By 2},
  __markedentry = {[mac:]},
  abstract      = {A Software Product Line is a set of software systems of a domain, which share some common features but also have significant variability. A feature model is a variability modeling artifact which represents differences among software products with respect to variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by selecting features in the feature model (referred to as the configuration process) and by instantiating the reference model. However, feature model configuration can be a cumbersome task because: 1) feature models may consist of a large number of features, which are hard to comprehend and maintain; and 2) many factors including technical limitations, implementation costs, stakeholders’ requirements and expectations must be considered in the configuration process. Recognizing these issues, a significant amount of research efforts has been dedicated to different aspects of feature model configuration such as automating the configuration process. Several approaches have been proposed to alleviate the feature model configuration challenges through applying visualization and interaction techniques. However, there have been limited empirical insights available into the impact of visualization and interaction techniques on the feature model configuration process. In this paper, we present a set of visualization and interaction interventions for representing and configuring feature models, which are then empirically validated to measure the impact of the proposed interventions. An empirical study was conducted by following the principles of control experiments in software engineering and by applying the well-known software quality standard ISO 9126 to operationalize the variables investigated in the experiment. The results of the empirical study revealed that the employed visualization and interaction interventions significantly improved completion time of comprehension and changing of the feature model configuration. Additionally, according to results, the proposed interventions are easy-to-use and easy-to-learn for the participants. © 2015, Springer Science+Business Media New York.},
  comment       = {38},
  document_type = {Article},
  doi           = {10.1007/s10664-014-9353-5},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925275030&doi=10.1007%2fs10664-014-9353-5&partnerID=40&md5=985f277899e4fd1ea4af6e2b70d33f32},
}

@Article{Saeed2016a,
  author        = {Mazin Saeed and Faisal Saleh and Sadiq Al-Insaif and Mohamed El-Attar},
  title         = {Empirical validating the cognitive effectiveness of a new feature diagrams visual syntax},
  journal       = {Information and Software Technology},
  year          = {2016},
  volume        = {71},
  pages         = {1 - 26},
  issn          = {0950-5849},
  __markedentry = {[mac:6]},
  abstract      = {Context
Feature models are commonly used to capture and communicate the commonality and variability of features in a Software Product Line. The core component of Feature models is feature diagrams, which graphically depict features in a hierarchical form. In previous work we have proposed a new notation that aims to improve the cognitive effectiveness of feature diagrams.
Objective
The objective of this paper is to empirically validate the cognitive effectiveness of the new feature diagrams notation in comparison to its original form.
Methods
We use two distinct empirical user-studies to validate the new notation. The first empirical study uses the survey approach while the second study is a subject-based experiment. The survey study investigates the semantic transparency of the new notation while the second study investigates the speed and accuracy of reading the notation.
Results
The results of the studies indicate that the proposed changes have significantly improved its cognitive effectiveness.
Conclusions
The cognitive effectiveness of feature diagrams has been improved, however there remains further research for full acceptance of the new notation by its potential user community.},
  comment       = {26},
  doi           = {https://doi.org/10.1016/j.infsof.2015.10.012},
  keywords      = {Feature models, Visual syntax evaluation, Software product lines},
  url           = {http://www.sciencedirect.com/science/article/pii/S0950584915001780},
}

@Article{Reinhartz-Berger2014,
  author        = {Reinhartz-Berger, I. and Sturm, A.},
  title         = {Comprehensibility of UML-based software product line specifications A controlled experiment},
  journal       = {Empirical Software Engineering},
  year          = {2014},
  volume        = {19},
  number        = {3},
  pages         = {678-713},
  note          = {cited By 6},
  __markedentry = {[mac:]},
  abstract      = {Software Product Line Engineering (SPLE) deals with developing artifacts that capture the common and variable aspects of software product families. Domain models are one kind of such artifacts. Being developed in early stages, domain models need to specify commonality and variability and guide the reuse of the artifacts in particular software products. Although different modeling methods have been proposed to manage and support these activities, the assessment of these methods is still in an inceptive stage. In this work, we examined the comprehensibility of domain models specified in ADOM, a UML-based SPLE method. In particular, we conducted a controlled experiment in which 116 undergraduate students were required to answer comprehension questions regarding a domain model that was equipped with explicit reuse guidance and/or variability specification. We found that explicit specification of reuse guidance within the domain model helped understand the model, whereas explicit specification of variability increased comprehensibility only to a limited extent. Explicit specification of both reuse guidance and variability often provided intermediate results, namely, results that were better than specification of variability without reuse guidance, but worse than specification of reuse guidance without variability. All these results were perceived in different UML diagram types, namely, use case, class, and sequence diagrams and for different commonality-, variability-, and reuse-related aspects. © 2012 Springer Science+Business Media, LLC.},
  comment       = {36},
  document_type = {Article},
  doi           = {10.1007/s10664-012-9234-8},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899943828&doi=10.1007%2fs10664-012-9234-8&partnerID=40&md5=8c6715fe527f714fb9a98aa9dd230798},
}

@Article{Reinhartz-Berger2017,
  author        = {Iris Reinhartz-Berger and Kathrin Figl and Øystein Haugen},
  title         = {Investigating styles in variability modeling: Hierarchical vs. constrained styles},
  journal       = {Information and Software Technology},
  year          = {2017},
  volume        = {87},
  pages         = {81 - 102},
  issn          = {0950-5849},
  __markedentry = {[mac:6]},
  abstract      = {Context
A common way to represent product lines is with variability modeling. Yet, there are different ways to extract and organize relevant characteristics of variability. Comprehensibility of these models and the ease of creating models are important for the efficiency of any variability management approach.
Objective
The goal of this paper is to investigate the comprehensibility of two common styles to organize variability into models – hierarchical and constrained – where the dependencies between choices are specified either through the hierarchy of the model or as cross-cutting constraints, respectively.
Method
We conducted a controlled experiment with a sample of 90 participants who were students with prior training in modeling. Each participant was provided with two variability models specified in Common Variability Language (CVL) and was asked to answer questions requiring interpretation of provided models. The models included 9–20 nodes and 8–19 edges and used the main variability elements. After answering the questions, the participants were asked to create a model based on a textual description.
Results
The results indicate that the hierarchical modeling style was easier to comprehend from a subjective point of view, but there was also a significant interaction effect with the degree of dependency in the models, that influenced objective comprehension. With respect to model creation, we found that the use of a constrained modeling style resulted in higher correctness of variability models.
Conclusions
Prior exposure to modeling style and the degree of dependency among elements in the model determine what modeling style a participant chose when creating the model from natural language descriptions. Participants tended to choose a hierarchical style for modeling situations with high dependency and a constrained style for situations with low dependency. Furthermore, the degree of dependency also influences the comprehension of the variability model.},
  comment       = {22},
  doi           = {https://doi.org/10.1016/j.infsof.2017.01.012},
  keywords      = {Variability modeling, Feature modeling, Comprehensibility, Hierarchical modeling, Textual constraints, Cognitive aspects, Empirical research, Product line engineering},
  url           = {http://www.sciencedirect.com/science/article/pii/S0950584917300800},
}

@Article{Cetina2013a,
  author        = {Carlos Cetina and Pau Giner and Joan Fons and Vicente Pelechano},
  title         = {Prototyping Dynamic Software Product Lines to evaluate run-time reconfigurations},
  journal       = {Science of Computer Programming},
  year          = {2013},
  volume        = {78},
  number        = {12},
  pages         = {2399 - 2413},
  issn          = {0167-6423},
  note          = {Special Section on International Software Product Line Conference 2010 and Fundamentals of Software Engineering (selected papers of FSEN 2011)},
  __markedentry = {[mac:6]},
  abstract      = {Dynamic Software Product Lines (DSPL) encompass systems that are capable of modifying their own behavior with respect to changes in their operating environment by using run-time reconfigurations. A failure in these reconfigurations can directly impact the user experience since the reconfigurations are performed when the system is already under the users control. In this work, we prototype a Smart Hotel DSPL to evaluate the reliability-based risk of the DSPL reconfigurations, specifically, the probability of malfunctioning (Availability) and the consequences of malfunctioning (Severity). This DSPL prototype was performed with the participation of human subjects by means of a Smart Hotel case study which was deployed with real devices. Moreover, we successfully identified and addressed two challenges associated with the involvement of human subjects in DSPL prototyping: enabling participants to (1) trigger the run-time reconfigurations and to (2) understand the effects of the reconfigurations. The evaluation of the case study reveals positive results regarding both Availability and Severity. However, the participant feedback highlights issues with recovering from a failed reconfiguration or a reconfiguration triggered by mistake. To address these issues, we discuss some guidelines learned in the case study. Finally, although the results achieved by the DSPL may be considered satisfactory for its particular domain, DSPL engineers must provide users with more control over the reconfigurations or the users will not be comfortable with DSPLs.},
  comment       = {15},
  doi           = {https://doi.org/10.1016/j.scico.2012.06.007},
  keywords      = {Dynamic Software Product Line, Variability modeling, Smart Hotel},
  url           = {http://www.sciencedirect.com/science/article/pii/S0167642312001189},
}

@Article{Bonifacio2017,
  author        = {Bonifácio, R. and Borba, P. and Ferraz, C. and Accioly, P.},
  title         = {Empirical assessment of two approaches for specifying software product line use case scenarios},
  journal       = {Software and Systems Modeling},
  year          = {2017},
  volume        = {16},
  number        = {1},
  pages         = {97-123},
  note          = {cited By 0},
  __markedentry = {[mac:]},
  abstract      = {Modularity benefits, including the independent maintenance and comprehension of individual modules, have been widely advocated. However, empirical assessments to investigate those benefits have mostly focused on source code, and thus, the relevance of modularity to earlier artifacts is still not so clear (such as requirements and design models). In this paper, we use a multimethod technique, including designed experiments, to empirically evaluate the benefits of modularity in the context of two approaches for specifying product line use case scenarios: PLUSS and MSVCM. The first uses an annotative approach for specifying variability, whereas the second relies on aspect-oriented constructs for separating common and variant scenario specifications. After evaluating these approaches through the specifications of several systems, we find out that MSVCM reduces feature scattering and improves scenario cohesion. These results suggest that evolving a product line specification using MSVCM requires only localized changes. On the other hand, the results of six experiments reveal that MSVCM requires more time to derive the product line specifications and, contrasting with the modularity results, reduces the time to evolve a product line specification only when the subjects have been well trained and are used to the task of evolving product line specifications. © 2015, Springer-Verlag Berlin Heidelberg.},
  comment       = {27},
  document_type = {Article},
  doi           = {10.1007/s10270-015-0471-3},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929900234&doi=10.1007%2fs10270-015-0471-3&partnerID=40&md5=f2635739cdc8744117607019ed6aa88a},
}

@Article{Bagheri2011a,
  author        = {Bagheri, E. and Gasevic, D.},
  title         = {Assessing the maintainability of software product line feature models using structural metrics},
  journal       = {Software Quality Journal},
  year          = {2011},
  volume        = {19},
  number        = {3},
  pages         = {579-612},
  note          = {cited By 73},
  __markedentry = {[mac:]},
  abstract      = {A software product line is a unified representation of a set of conceptually similar software systems that share many common features and satisfy the requirements of a particular domain. Within the context of software product lines, feature models are tree-like structures that are widely used for modeling and representing the inherent commonality and variability of software product lines. Given the fact that many different software systems can be spawned from a single software product line, it can be anticipated that a low-quality design can ripple through to many spawned software systems. Therefore, the need for early indicators of external quality attributes is recognized in order to avoid the implications of defective and low-quality design during the late stages of production. In this paper, we propose a set of structural metrics for software product line feature models and theoretically validate them using valid measurement-theoretic principles. Further, we investigate through controlled experimentation whether these structural metrics can be good predictors (early indicators) of the three main subcharacteristics of maintainability: analyzability, changeability, and understandability. More specifically, a four-step analysis is conducted: (1) investigating whether feature model structural metrics are correlated with feature model maintainability through the employment of classical statistical correlation techniques; (2) understanding how well each of the structural metrics can serve as discriminatory references for maintainability; (3) identifying the sufficient set of structural metrics for evaluating each of the subcharacteristics of maintainability; and (4) evaluating how well different prediction models based on the proposed structural metrics can perform in indicating the maintainability of a feature model. Results obtained from the controlled experiment support the idea that useful prediction models can be built for the purpose of evaluating feature model maintainability using early structural metrics. Some of the structural metrics show significant correlation with the subjective perception of the subjects about the maintainability of the feature models. © 2010 Springer Science+Business Media, LLC.},
  comment       = {34},
  document_type = {Article},
  doi           = {10.1007/s11219-010-9127-2},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958248566&doi=10.1007%2fs11219-010-9127-2&partnerID=40&md5=e0e2572c8e9a517f7df77ecfd32da223},
}

@Article{Thurimella2013a,
  author        = {Anil Kumar Thurimella and Bernd Brügge},
  title         = {A mixed-method approach for the empirical evaluation of the issue-based variability modeling},
  journal       = {Journal of Systems and Software},
  year          = {2013},
  volume        = {86},
  number        = {7},
  pages         = {1831 - 1849},
  issn          = {0164-1212},
  __markedentry = {[mac:6]},
  abstract      = {Background
Variability management is the fundamental part of software product line engineering, which deals with customization and reuse of artifacts for developing a family of systems. Rationale approaches structure decision-making by managing the tacit-knowledge behind decisions. This paper reports a quasi-experiment for evaluating a rationale enriched collaborative variability management methodology called issue-based variability modeling.
Objective
We studied the interaction of stakeholders with issue-based modeling to evaluate its applicability in requirements engineering teams. Furthermore, we evaluated the reuse of rationale while instantiating and changing variability.
Approach
We enriched a quasi-experimental design with a variety of methods found in case study research. A sample of 258 students was employed with data collection and analysis based on a mix of qualitative and quantitative methods. Our study was performed in two phases: the first phase focused on variability identification and instantiation, while the second phase included tasks on variability evolution.
Results
We obtained strong empirical evidence on reuse patterns for rationale during instantiation and evolution of variability. The tabular representations used by rationale modeling are learnable and usable in teams of diverse backgrounds.},
  comment       = {19},
  doi           = {https://doi.org/10.1016/j.jss.2013.01.038},
  keywords      = {Rationale management, Software product lines, Variability, Requirements engineering, Empirical software engineering, Mixed-methods},
  url           = {http://www.sciencedirect.com/science/article/pii/S0164121213000186},
}

@Article{Feigenspan2013,
  author        = {Feigenspan, J. and Kästner, C. and Apel, S. and Liebig, J. and Schulze, M. and Dachselt, R. and Papendieck, M. and Leich, T. and Saake, G.},
  title         = {Do background colors improve program comprehension in the #ifdef hell?},
  journal       = {Empirical Software Engineering},
  year          = {2013},
  volume        = {18},
  number        = {4},
  pages         = {699-745},
  note          = {cited By 35},
  __markedentry = {[mac:]},
  abstract      = {Software-product-line engineering aims at the development of variable and reusable software systems. In practice, software product lines are often implemented with preprocessors. Preprocessor directives are easy to use, and many mature tools are available for practitioners. However, preprocessor directives have been heavily criticized in academia and even referred to as "#ifdef hell", because they introduce threats to program comprehension and correctness. There are many voices that suggest to use other implementation techniques instead, but these voices ignore the fact that a transition from preprocessors to other languages and tools is tedious, erroneous, and expensive in practice. Instead, we and others propose to increase the readability of preprocessor directives by using background colors to highlight source code annotated with ifdef directives. In three controlled experiments with over 70 subjects in total, we evaluate whether and how background colors improve program comprehension in preprocessor-based implementations. Our results demonstrate that background colors have the potential to improve program comprehension, independently of size and programming language of the underlying product. Additionally, we found that subjects generally favor background colors. We integrate these and other findings in a tool called FeatureCommander, which facilitates program comprehension in practice and which can serve as a basis for further research. © 2012 Springer Science+Business Media, LLC.},
  comment       = {47},
  document_type = {Article},
  doi           = {10.1007/s10664-012-9208-x},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879846095&doi=10.1007%2fs10664-012-9208-x&partnerID=40&md5=76165de9ec8580474e8390c79a7ad728},
}

@Article{Accioly2014,
  author        = {Accioly, P. and Borba, P. and Bonifácio, R.},
  title         = {Controlled experiments comparing black-box testing strategies for software product lines},
  journal       = {Journal of Universal Computer Science},
  year          = {2014},
  volume        = {20},
  number        = {5},
  pages         = {615-639},
  note          = {cited By 1},
  __markedentry = {[mac:]},
  abstract      = {SPL testing has been considered a challenging task, mainly due to the diversity of products that might be generated from an SPL. To deal with this problem, techniques for specifying and deriving product specific functional test cases have been proposed. However, there is little empirical evidence of the benefits and drawbacks of these techniques. To provide this kind of evidence, in a previous work we conducted an empirical study that compared two design techniques for black-box manual testing, a generic technique that we have observed in an industrial test execution environment, and a product specific technique whose functional test cases could be derived using any SPL approach that considers variations in functional tests. Besides revisiting the first study, here we present a second study that reinforce our findings and brings new insights to our investigation. Both studies indicate that specific test cases improve test execution productivity and quality. © J.UCS.},
  comment       = {25},
  document_type = {Article},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904764309&partnerID=40&md5=112aba25b5f4f038fd0f7ce17b051afe},
}

@Article{Ahmed2008d,
  author        = {Ahmed, F. and Capretz, L.F.},
  title         = {The software product line architecture: An empirical investigation of key process activities},
  journal       = {Information and Software Technology},
  year          = {2008},
  volume        = {50},
  number        = {11},
  pages         = {1098-1113},
  note          = {cited By 20},
  __markedentry = {[mac:]},
  abstract      = {Software architecture has been a key area of concern in software industry due to its profound impact on the productivity and quality of software products. This is even more crucial in case of software product line, because it deals with the development of a line of products sharing common architecture and having controlled variability. The main contributions of this paper is to increase the understanding of the influence of key software product line architecture process activities on the overall performance of software product line by conducting a comprehensive empirical investigation covering a broad range of organizations currently involved in the business of software product lines. This is the first study to empirically investigate and demonstrate the relationships between some of the software product line architecture process activities and the overall software product line performance of an organization at the best of our knowledge. The results of this investigation provide empirical evidence that software product line architecture process activities play a significant role in successfully developing and managing a software product line. © 2007 Elsevier B.V. All rights reserved.},
  comment       = {16},
  document_type = {Article},
  doi           = {10.1016/j.infsof.2007.10.013},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-49549123847&doi=10.1016%2fj.infsof.2007.10.013&partnerID=40&md5=63a5afabfc5f33af279aa8e53b82a03c},
}

@Article{Feigenspan2012a,
  author        = {Feigenspan, J. and Schulze, M. and Papendieck, M. and Kästner, C. and Dachselt, R. and Köppen, V. and Frisch, M. and Saake, G.},
  title         = {Supporting program comprehension in large preprocessor-based software product lines},
  journal       = {IET Software},
  year          = {2012},
  volume        = {6},
  number        = {6},
  pages         = {488-501},
  note          = {cited By 5},
  __markedentry = {[mac:]},
  abstract      = {Software product line (SPL) engineering provides an effective mechanism to implement variable software. However, using preprocessors to realise variability, which is typical in industry, is heavily criticised, because it often leads to obfuscated code. Using background colours to highlight code annotated with preprocessor statements to support comprehensibility has proved to be effective, however, scalability to large SPLs is questionable. The authors' aim is to implement and evaluate scalable usage of background colours for industrial-sized SPLs. They designed and implemented scalable concepts in a tool called FeatureCommander. To evaluate its effectiveness, the authors conducted a controlled experiment with a large real-world SPL with over 99 000 lines of code and 340 features. They used a within-subjects design with treatment colours and no colours. They compared correctness and response time of tasks for both treatments. For certain kinds of tasks, background colours improve program comprehension. Furthermore, the subjects generally favour background colours compared with no background colours. In addition, the subjects who worked with background colours had to use the search functions less frequently. The authors show that background colours can improve program comprehension in large SPLs. Based on these encouraging results, they continue their work on improving program comprehension in large SPLs. © 2012 The Institution of Engineering and Technology.},
  comment       = {14},
  document_type = {Article},
  doi           = {10.1049/iet-sen.2011.0172},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870419356&doi=10.1049%2fiet-sen.2011.0172&partnerID=40&md5=4b531e8f5d4a9751fbc0361641fbb8d4},
}

@Article{Liu2017,
  author        = {Yuzhou Liu and Lei Liu and Huaxiao Liu and Xiaoyu Wang and Hongji Yang},
  title         = {Mining domain knowledge from app descriptions},
  journal       = {Journal of Systems and Software},
  year          = {2017},
  volume        = {133},
  pages         = {126 - 144},
  issn          = {0164-1212},
  __markedentry = {[mac:6]},
  abstract      = {Domain analysis aims at gaining knowledge to a particular domain in the early stage of software development. A key challenge in domain analysis is to extract features automatically from related product artifacts. Compared with other kinds of artifacts, high volume of descriptions can be collected from App marketplaces (such as Google Play and Apple Store) easily when developing a new mobile application (App), so it is essential for the success of domain analysis to gain features and relationships from them using data analysis techniques. In this paper, we propose an approach to mine domain knowledge from App descriptions automatically, where the information of features in a single App description is firstly extracted and formally described by a Concern-based Description Model (CDM), which is based on predefined rules of feature extraction and a modified topic modeling method; then the overall knowledge in the domain is identified by classifying, clustering and merging the knowledge in the set of CDMs and topics, and the results are formalized by a Data-based Raw Domain Model (DRDM). Furthermore, we propose a quantified evaluation method for prioritizing the knowledge in DRDM. The proposed approach is validated by a series of experiments.},
  comment       = {19},
  doi           = {https://doi.org/10.1016/j.jss.2017.08.024},
  keywords      = {Domain analysis, Feature extraction, App descriptions, Data analysis},
  url           = {http://www.sciencedirect.com/science/article/pii/S0164121217301784},
}

@Article{Wang2013a,
  author        = {Wang, Y. and Kobsa, A.},
  title         = {A PLA-based privacy-enhancing user modeling framework and its evaluation},
  journal       = {User Modeling and User-Adapted Interaction},
  year          = {2013},
  volume        = {23},
  number        = {1},
  pages         = {41-82},
  note          = {cited By 6},
  __markedentry = {[mac:]},
  abstract      = {Reconciling personalization with privacy has been a continuing interest in user modeling research. This aim has computational, legal and behavioral/attitudinal ramifications. We present a dynamic privacy-enhancing user modeling framework that supports compliance with users' individual privacy preferences and with the privacy laws and regulations that apply to each user. The framework is based on a software product line architecture. It dynamically selects personalization methods during runtime that meet the current privacy constraints. Since dynamic architectural reconfiguration is typically resource-intensive, we conducted a performance evaluation with four implementations of our system that vary two factors. The results demonstrate that at least one implementation of our approach is technically feasible with comparatively modest additional resources, even for websites with the highest traffic today. To gauge user reactions to privacy controls that our framework enables, we also conducted a controlled experiment that allowed one group of users to specify privacy preferences and view the resulting effects on employed personalization methods. We found that users in this treatment group utilized this feature, deemed it useful, and had fewer privacy concerns as measured by higher disclosure of their personal data. © 2012 Springer Science+Business Media B.V.},
  comment       = {42},
  document_type = {Article},
  doi           = {10.1007/s11257-011-9114-8},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872381970&doi=10.1007%2fs11257-011-9114-8&partnerID=40&md5=1a3a96d04f816a8a746cd93b932acbf8},
}

@Comment{jabref-meta: databaseType:bibtex;}
